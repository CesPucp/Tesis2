{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Importar en csv Test 2%\n",
    "import pandas as pd\n",
    "data_test=pd.read_csv('DataTest2%.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coautores=[]\n",
    "#########################\n",
    "coautor=data_test.Coautor\n",
    "#########################\n",
    "coautor.reset_index(drop=True, inplace=True)\n",
    "for r in coautor:\n",
    "    sep= r.split(',')\n",
    "    m= len(sep)\n",
    "    aux=[]\n",
    "    for i in range(0,m):\n",
    "        if i==m-1:\n",
    "            aux.append(int(sep[i][2:-2]))\n",
    "        else:\n",
    "            aux.append(int(sep[i][2:-1]))\n",
    "    coautores.append(aux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3151"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(coautores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3151"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Leer los abstracts del data test\n",
    "#abstract\n",
    "ab=[]\n",
    "############################\n",
    "abstract=data_test.Abstract\n",
    "############################\n",
    "abstract.reset_index(drop=True, inplace=True)\n",
    "\n",
    "for r in abstract:\n",
    "    sep= r.split(',')\n",
    "    m= len(sep)\n",
    "    aux=[]\n",
    "    for i in range(0,m):\n",
    "        if i==m-1:\n",
    "            aux.append(sep[i][2:-2])\n",
    "        else:\n",
    "            aux.append(sep[i][2:-1])\n",
    "    ab.append(aux)\n",
    "len(ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3151"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abst=[]\n",
    "for r in ab:\n",
    "    #print(r)\n",
    "    aux=' '.join(r)\n",
    "    abst.append(aux)\n",
    "len(abst)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fluctuations glacier mass volume indicative changes climate system also strongly affect regional climate hydrology explore possible relationships radial growth schrenk spruce picea schrenkiana fisch et mey mass balance tsentralniy tuyuksuyskiy ts tuyuksuyskiy glacier located northern slopes tianshan mountains arid central asia attempt reconstruct historical mass balance variability ts tuyuksuyskiy glacier using tree-ring widths stable carbon isotope chronologies reconstruction able explain 62.1 variance annual glacier mass balance record 1965–2014 calibration period also analyzed centennial mass balance variability linkages climate change ts.tuyuksuyskiy glacier negative annual mass balance years since 1968 undergone rapid longest melting process past 166 years mass balance change glacier controlled combination temperature precipitation conditions study could useful detailed glaciological hydrological climatological assessments portion tianshan mountains 2018 authors'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abst[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import community\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "from collections import Counter\n",
    "#Creación de grafo con peso de abstract\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n"
     ]
    }
   ],
   "source": [
    "import community\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "from collections import Counter\n",
    "#Creación de grafo con peso de abstract\n",
    "\n",
    "#nlp = spacy.load('en_core_web_lg')\n",
    "g_abs=nx.Graph()\n",
    "ind=0\n",
    "\n",
    "autor=data_test.IdAutor\n",
    "autor.reset_index(drop=True, inplace=True)\n",
    "\n",
    "for node in autor:\n",
    "    g_abs.add_node(node)\n",
    "\n",
    "for edge in coautores:\n",
    "    counter=Counter(edge)\n",
    "    #dist=levenshteinDistance()\n",
    "    for elem in counter:\n",
    "        encontrado=0\n",
    "        if elem == autor[ind]:\n",
    "            encontrado=0\n",
    "        else:\n",
    "            for a in autor:\n",
    "                if elem== a:\n",
    "                    encontrado=1\n",
    "        if encontrado:\n",
    "            n=0\n",
    "            for item in autor:\n",
    "                if (item==elem):\n",
    "                    indice=n\n",
    "                n+=1\n",
    "            \n",
    "            doc1 = nlp(abst[ind])\n",
    "            doc2 = nlp(abst[indice])\n",
    "            dist= doc1.similarity(doc2)\n",
    "            \n",
    "            g_abs.add_edge(autor[ind], elem, weight=dist)\n",
    "    ind+=1\n",
    "    if (ind%100)==0: print (ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: Graph\n",
      "Number of nodes: 3151\n",
      "Number of edges: 172\n",
      "Average degree:   0.1092\n"
     ]
    }
   ],
   "source": [
    "print (nx.info(g_abs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end\n",
      "end\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "#DBSCAN\n",
    "import numpy as np\n",
    "# Conveniently, networkx has a method for finding the Laplacian\n",
    "laplacian = nx.laplacian_matrix(g_abs)\n",
    "print(\"end\")\n",
    "# Use numpy to compute the Fiedler vector, which corresponds to the\n",
    "# second smallest eigenvalue of the Laplacian\n",
    "w, v = np.linalg.eig(laplacian.todense())\n",
    "print(\"end\")\n",
    "algebraic_connectivity = w[1]\n",
    "# Neat measure of how tight the graph is\n",
    "print(\"end\")\n",
    "fiedler_vector = v[:,1].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cesarorellananoriega/anaconda3/lib/python3.6/site-packages/numpy/core/numeric.py:501: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "/Users/cesarorellananoriega/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:433: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  array = np.array(array, dtype=dtype, order=order, copy=copy)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "db = DBSCAN(eps=0.9, min_samples=7).fit(fiedler_vector.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = db.labels_\n",
    "# Number of clusters in labels, ignoring noise if present.\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "n_clusters_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 3151})"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c=Counter(labels)\n",
    "c"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
